\section{Implementation Details}\label{sec:implementation}

\begin{itemize}
\item Began with brute force, slow autofocus algorithm to use as a baseline
\subitem Take “algorithm” figure from technical report
\item Runtime was prohibitively slow and computationally intense
  \item Sought optimizations to allow for better testing and usability
  \item We generate SAR images using images generated by the same process as used in (cite Ian + Colin)
\item Used standard gradient descent iteration (equation)
  \item Bulk of computational complexity contained in calculation of the gradient of the entropy function
  \subitem Optimized this significantly through parallelization and precomputation
\item Used finite difference approximation computed via (algorithm)
  \subitem Matlab implementation of gradient descent
  \subitem C++ called from Matlab using Mex function, implementing gradient descent
    \subsubitem Passed computation of each component of the gradient vector to its own thread
    \subsubitem Reused computations from $H_0$ to significantly reduce computations for each $H_i$ (divided num ops by K)
  \subitem CUDA implementation further optimized the algorithm
    \subsubitem Used a NVIDIA processor with 2GB of global memory
  \end{itemize}
