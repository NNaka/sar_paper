\section{Introduction}\label{sec:introduction}

Synthetic aperture radar (SAR) has many applications such as reconnaissance and
disaster relief. Smoke, cloud cover, or other atmospheric interference that
traditionally obscure airborne images do not impact SAR images. Moreover, since
SAR images provide their own illumination, they work well at all hours.  SAR
image processing is composed of two high level operations: image formation and
focusing. Image formation involves collecting radar and positional data and, via
signal processing techniques, forming a coherent phase history.  This work
uses the backprojection algorithm~\cite{bp} to form the history. The resulting
image, however, is subject to errors due to inaccuracies in the positional
system as well as atmospheric propagation delays~\cite{ash2012autofocus}.
Autofocus, therefore, attempts to correct these errors. Phase gradient autofocus
(PGA)~\cite{wahl1994phase} yields compelling results but relies on specific
assumptions which limit its applicability~\cite{ash2012autofocus}. Instead,
other techniques model these errors as some unknown phase shift,
$\phi$, for each pulse in the phase history.  The autofocus algorithm,
therefore, seeks a set of phases, $\phib$, which maximizes image quality.
Finding such a set has been well researched with many techniques in the
literature~\cite{kragh2006monotonic, ash2012autofocus, kragh2009minimum,
morrison2007sar, Eichel:89, less_mem_high_eff_autofocus}.  This work builds upon
the minimum-entropy autofocus technique proposed in~\cite{kragh2006monotonic} by
developing highly parallelized implementations of the gradient descent algorithm
discussed.

The remainder of this paper is organized as follows.
Section~\ref{sec:relatedwork} details the related literature and provides
context for this paper. Sections~\ref{sec:implementation} and~\ref{sec:results}
describe the general implementation techniques and optimizations employed, and
the performance results we obtained, respectively. Section~\ref{sec:futurework}
discusses the need for continued optimizations and improvements. Finally, we
conclude in the last section.

\subsection{Contributions}

This work contributes two implementations of the gradient descent entropy
minimization autofocus algorithm for SAR images and compares their efficacy to
current solutions in the literature. A tuned C++ implementation which runs on a
scalable number of native CPU threads demonstrates over $50\times$ improvement in
performance compared to a MATLAB implementation. Also, we measured a CUDA-based
GPU implementation, exploiting the regular parallelism of the gradient
computation. We achieved as much as an $80\times$ improvement in performance
for various pulse history sizes.
